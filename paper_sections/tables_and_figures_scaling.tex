% LaTeX Tables and Figures for Section 5.3 Scaling Analysis
% Ready for direct integration into the research paper

% ============================================================================
% Table 4: Query Latency Scaling
% ============================================================================
\begin{table}[ht]
\centering
\caption{Query Latency Scaling Across Corpus Sizes (Top-K=3, P50 Latency)}
\label{tab:query_latency_scaling}
\begin{tabular}{lrrrrrr}
\toprule
\textbf{Database} & \textbf{175} & \textbf{5.6K} & \textbf{70K} & \textbf{345K} & \textbf{2.2M} & \textbf{Scaling} \\
                  & \textbf{chunks} & \textbf{chunks} & \textbf{chunks} & \textbf{chunks} & \textbf{chunks} & \textbf{Factor} \\
\midrule
Chroma     & 7.3 ms  & 8.2 ms   & 9.1 ms   & \textbf{6.4 ms}$^{\star}$  & TIMEOUT & 0.88× \\
FAISS      & 8.0 ms  & 10.9 ms  & 12.6 ms  & 17.9 ms  & \textbf{61.5 ms}$^{\star}$ & 7.7× \\
Qdrant     & 9.8 ms  & 12.1 ms  & 24.8 ms  & 38.3 ms  & TIMEOUT & 3.9× \\
Weaviate   & 11.5 ms & 15.3 ms  & 29.6 ms  & 48.0 ms  & TIMEOUT & 4.2× \\
Milvus     & 10.2 ms & 13.8 ms  & 28.1 ms  & 41.3 ms  & TIMEOUT & 4.0× \\
OpenSearch & 17.9 ms & 32.4 ms  & 64.7 ms  & FAILED   & FAILED  & N/A \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Scaling factor = (latency at max proven scale) / (latency at baseline)
\item $^{\star}$ Successfully completed at 2.2M chunks
\item TIMEOUT: Exceeded 2-hour time limit
\end{tablenotes}
\end{table}

% ============================================================================
% Table 5: Ingestion Performance
% ============================================================================
\begin{table}[ht]
\centering
\caption{Ingestion Performance and Throughput Consistency Across Scales}
\label{tab:ingestion_scaling}
\begin{tabular}{lrrrr}
\toprule
\textbf{Database} & \textbf{175 chunks} & \textbf{345K chunks} & \textbf{2.2M chunks} & \textbf{Throughput} \\
                  & \textbf{(ch/s)} & \textbf{(ch/s)} & \textbf{(ch/s)} & \textbf{CV (\%)} \\
\midrule
FAISS      & 345  & 391  & \textbf{408}$^{\star}$ & \textbf{2.5} \\
Chroma     & 328  & \textbf{310}$^{\star}$ & TIMEOUT & 4.1 \\
Qdrant     & 156  & 134  & TIMEOUT & 8.7 \\
Weaviate   & 142  & 102  & TIMEOUT & 12.3 \\
Milvus     & 138  & 98   & TIMEOUT & 11.9 \\
OpenSearch & 87   & FAILED & FAILED & N/A \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item ch/s = chunks per second; CV = Coefficient of variation (lower is better)
\item $^{\star}$ Best-in-class performance for that scale
\item Throughput CV calculated across all successful corpus sizes (lower = more consistent)
\end{tablenotes}
\end{table}

% ============================================================================
% Table 6: Scaling Complexity Analysis
% ============================================================================
\begin{table}[ht]
\centering
\caption{Estimated Scaling Complexity from Power-Law Regression}
\label{tab:scaling_complexity}
\begin{tabular}{lccll}
\toprule
\textbf{Database} & \textbf{Exponent} & \textbf{$R^2$} & \textbf{Complexity} & \textbf{Proven Range} \\
                  & \textbf{($\alpha$)} & & \textbf{Class} & \\
\midrule
Chroma     & 0.02 $\pm$ 0.11 & 0.12 & Constant$^{\star\star\star}$  & 175 -- 345K chunks \\
FAISS      & 0.48 $\pm$ 0.06 & 0.96 & Sub-linear$^{\star}$          & 175 -- 2.2M chunks \\
Qdrant     & 0.68 $\pm$ 0.08 & 0.94 & Moderate                      & 175 -- 345K chunks \\
Weaviate   & 0.72 $\pm$ 0.09 & 0.93 & Moderate                      & 175 -- 345K chunks \\
Milvus     & 0.70 $\pm$ 0.08 & 0.94 & Moderate                      & 175 -- 345K chunks \\
OpenSearch & 1.03 $\pm$ 0.14 & 0.89 & Linear (poor)                 & 175 -- 70K chunks \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Scaling model: latency $\propto N^\alpha$ where $N$ is corpus size
\item $\alpha < 0.5$: Sub-linear (excellent); $\alpha \approx 0$: Constant (exceptional)
\item $0.5 < \alpha < 0.9$: Moderate; $\alpha \approx 1.0$: Linear (poor for large scale)
\end{tablenotes}
\end{table}

% ============================================================================
% Table 7: Maximum Proven Scale and Failure Modes
% ============================================================================
\begin{table}[ht]
\centering
\caption{Maximum Proven Scale and Observed Failure Modes}
\label{tab:scalability_limits}
\begin{tabular}{lcll}
\toprule
\textbf{Database} & \textbf{Max Proven} & \textbf{Status at} & \textbf{Failure Mode} \\
                  & \textbf{Scale} & \textbf{2.2M chunks} & \\
\midrule
FAISS      & 2.2M chunks & \textcolor{green}{\checkmark} Success (90 min) & None observed \\
Chroma     & 345K chunks & \textcolor{orange}{!} Timeout & Memory saturation, swap thrashing \\
Qdrant     & 345K chunks & \textcolor{orange}{!} Timeout & OOM kill, HNSW graph size \\
Weaviate   & 345K chunks & \textcolor{orange}{!} Timeout & OOM kill, HNSW graph size \\
Milvus     & 345K chunks & \textcolor{orange}{!} Timeout & OOM kill, HNSW graph size \\
OpenSearch & 70K chunks  & \textcolor{red}{\times} Failed at 345K & Index rebuild loop, segment merges \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item All experiments conducted on single Docker host with 16GB RAM limit
\item Timeout threshold: 2 hours per corpus size
\item OOM = Out-of-memory error
\end{tablenotes}
\end{table}

% ============================================================================
% Figure 6: Query Latency Scaling (Log-Log Plot)
% ============================================================================
\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{results/cross_database_comparison/query_latency_scaling.png}
\caption{Query latency scaling across corpus sizes (Top-K=3). Log-log plot reveals three performance classes: constant-time (Chroma, flat line), sub-linear (FAISS, gentle slope), and moderate degradation (Qdrant/Weaviate/Milvus). OpenSearch fails at 345K chunks. FAISS is the only database to successfully complete 2.2M chunks within the 2-hour timeout.}
\label{fig:query_latency_scaling}
\end{figure}

% ============================================================================
% Figure 7: Ingestion Performance Comparison
% ============================================================================
\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{results/cross_database_comparison/ingestion_comparison.png}
\caption{Ingestion throughput (chunks/second) and total time across corpus sizes. FAISS maintains constant throughput (~400 ch/s) across all scales. Chroma achieves highest absolute throughput at 345K chunks (310 ch/s), 2-3× faster than HNSW-based competitors. HNSW databases show 15-30\% degradation as corpus size increases.}
\label{fig:ingestion_comparison}
\end{figure}

% ============================================================================
% Figure 8: Detailed 345K Chunk Comparison
% ============================================================================
\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{results/cross_database_comparison/50k_detailed_comparison.png}
\caption{Four-panel detailed comparison at 345K chunks. (Top-left) Query latency: Chroma leads at 6.4ms, 6× faster than Qdrant/Weaviate. (Top-right) Throughput: Chroma achieves 144 QPS, 6-18× higher than competitors. (Bottom-left) Ingestion time: Chroma completes in 18.5 minutes, 2-3× faster than others. (Bottom-right) Memory usage: Chroma most efficient at 8.8GB, while Qdrant/Weaviate require 14-16GB.}
\label{fig:50k_detailed}
\end{figure}

% ============================================================================
% Figure 9: Latency Heatmap
% ============================================================================
\begin{figure}[ht]
\centering
\includegraphics[width=0.75\textwidth]{results/cross_database_comparison/latency_heatmap.png}
\caption{Latency heatmap visualization across databases and corpus sizes. Color intensity represents P50 query latency (lighter = faster). Chroma maintains consistently low latency (yellow) across all scales. FAISS shows gradual darkening with scale but completes all sizes. HNSW-based databases (Qdrant, Weaviate, Milvus) show increased latency (orange/red) at 70K and 345K. OpenSearch and timeout failures shown in gray.}
\label{fig:latency_heatmap}
\end{figure}

% ============================================================================
% Additional Supporting Material (Optional)
% ============================================================================

% If you want to include the FAISS scaling equation prominently:
\begin{equation}
\text{Latency}_{\text{FAISS}} \propto N^{0.48}, \quad R^2 = 0.96
\label{eq:faiss_scaling}
\end{equation}

% Memory footprint calculation (can be a standalone box/equation):
\begin{equation}
\begin{aligned}
\text{Memory}_{\text{HNSW}} &= \underbrace{N \times d \times 4}_{\text{vectors}} + \underbrace{N \times M \times 2 \times 8}_{\text{graph links}} + \underbrace{N \times 64}_{\text{metadata}} \\
&= 2.2\text{M} \times 384 \times 4 + 2.2\text{M} \times 16 \times 2 \times 8 + 2.2\text{M} \times 64 \\
&= 3.45\text{ GB} + 1.15\text{ GB} + 0.14\text{ GB} = 4.74\text{ GB (base)}
\end{aligned}
\label{eq:memory_footprint}
\end{equation}

% ============================================================================
% Sidebar/Box: Practical Recommendations (Optional formatting)
% ============================================================================
\begin{tcolorbox}[colback=blue!5!white, colframe=blue!75!black, title=Practical Database Selection Guidelines]
\textbf{Based on Corpus Size:}
\begin{itemize}
    \item \textbf{< 100K chunks}: Chroma or FAISS (both sub-10ms)
    \item \textbf{100K - 500K chunks}: Chroma (6ms, 144 QPS) or Qdrant (38ms, good ecosystem)
    \item \textbf{500K - 2M chunks}: FAISS (only proven option) or distributed HNSW
    \item \textbf{> 2M chunks}: FAISS flat index or aggressive HNSW sharding (4+ nodes)
\end{itemize}

\textbf{Avoid:}
\begin{itemize}
    \item OpenSearch for pure vector workloads (architectural mismatch)
    \item Single-node HNSW for > 1M chunks without high-memory instances (64GB+)
\end{itemize}
\end{tcolorbox}

% ============================================================================
% End of Tables and Figures
% ============================================================================
